{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4541af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import logging\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de84d315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 09:07:08,465 - root - INFO - Logging system initialized\n",
      "2025-05-20 09:07:08,467 - MscdaeModule - INFO - Mscdae module initialized\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "try:\n",
    "    # Ensure log directory exists\n",
    "    log_dir = os.path.dirname(os.path.abspath(\"logs/mscdae_train.log\"))\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    # Configure logging\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(\"logs/mscdae_train.log\", mode='a'),  # 追加模式\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    # Force output of initial log to confirm logging system is working\n",
    "    logging.info(\"Logging system initialized\")\n",
    "except Exception as e:\n",
    "    print(f\"Error setting up logging system: {str(e)}\")\n",
    "\n",
    "logger = logging.getLogger(\"MscdaeModule\")\n",
    "# Confirm logger is working properly\n",
    "logger.info(\"Mscdae module initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd6aacb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianPyramid(nn.Module):\n",
    "    def __init__(self, levels=3):\n",
    "        super(GaussianPyramid, self).__init__()\n",
    "        self.levels = levels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 生成高斯金字塔\n",
    "        pyramid = [x]\n",
    "        current = x\n",
    "        for _ in range(1, self.levels):\n",
    "            # 使用平均池化模拟高斯下采样\n",
    "            current = F.avg_pool2d(current, kernel_size=2, stride=2)\n",
    "            pyramid.append(current)\n",
    "        return pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d90f031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiScaleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MultiScaleConvBlock, self).__init__()\n",
    "        # 高斯金字塔\n",
    "        self.gaussian_pyramid = GaussianPyramid(levels=3)\n",
    "        \n",
    "        # 多尺度卷积\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=k, padding=k//2),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ) for k in [1, 3, 5]\n",
    "        ])\n",
    "        \n",
    "        # 计算输出通道数 (3个卷积核尺寸 * 3个金字塔级别 * out_channels)\n",
    "        self.output_channels = 3 * 3 * out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 获取高斯金字塔\n",
    "        pyramid_features = self.gaussian_pyramid(x)\n",
    "        \n",
    "        # 存储多尺度特征\n",
    "        multi_scale_features = []\n",
    "        \n",
    "        # 在每个金字塔层级应用卷积\n",
    "        for level in pyramid_features:\n",
    "            level_features = [conv(level) for conv in self.conv_layers]\n",
    "            \n",
    "            #报错\n",
    "            # 确保所有特征图尺寸一致\n",
    "            # if level != pyramid_features[0]:\n",
    "            #     level_features = [F.interpolate(feat, size=pyramid_features[0].shape[2:]) \n",
    "            #                     for feat in level_features]\n",
    "                \n",
    "            # 另一种修改方式:\n",
    "            if level.shape != pyramid_features[0].shape:\n",
    "                level_features = [F.interpolate(feat, size=pyramid_features[0].shape[2:]) \n",
    "                                for feat in level_features]\n",
    "\n",
    "            multi_scale_features.extend(level_features)\n",
    "        \n",
    "        # 特征融合\n",
    "        return torch.cat(multi_scale_features, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeb42a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSCDAE(nn.Module):\n",
    "    def __init__(self, input_channels=1):\n",
    "        super(MSCDAE, self).__init__()\n",
    "        \n",
    "        # 定义每层的通道数\n",
    "        self.encoder_channels = [input_channels, 16, 32]\n",
    "        \n",
    "        # 编码器\n",
    "        self.encoder_block1 = MultiScaleConvBlock(self.encoder_channels[0], self.encoder_channels[1])\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.encoder_block2 = MultiScaleConvBlock(self.encoder_block1.output_channels, self.encoder_channels[2])\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # 获取编码器最终输出通道数\n",
    "        self.bottleneck_channels = self.encoder_block2.output_channels\n",
    "        \n",
    "        # 解码器\n",
    "        self.upconv1 = nn.ConvTranspose2d(self.bottleneck_channels, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.decoder_block1 = MultiScaleConvBlock(32, 16)\n",
    "        self.upconv2 = nn.ConvTranspose2d(self.decoder_block1.output_channels, 16, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.decoder_block2 = MultiScaleConvBlock(16, 8)\n",
    "        self.final_conv = nn.Conv2d(self.decoder_block2.output_channels, input_channels, kernel_size=1)\n",
    "        \n",
    "        # 添加Sigmoid激活保证输出在[0,1]范围\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 添加噪声 (根据输入强度自适应)\n",
    "        noise_level = 0.1 * torch.mean(x)\n",
    "        noise = torch.randn_like(x) * noise_level\n",
    "        x_noisy = torch.clamp(x + noise, 0, 1)\n",
    "        \n",
    "        # 编码\n",
    "        e1 = self.encoder_block1(x_noisy)\n",
    "        e1_pool = self.pool1(e1)\n",
    "        e2 = self.encoder_block2(e1_pool)\n",
    "        e2_pool = self.pool2(e2)\n",
    "        \n",
    "        # 解码\n",
    "        d1 = self.upconv1(e2_pool)\n",
    "        d1_block = self.decoder_block1(d1)\n",
    "        d2 = self.upconv2(d1_block)\n",
    "        d2_block = self.decoder_block2(d2)\n",
    "        output = self.final_conv(d2_block)\n",
    "        \n",
    "        # 确保输出在[0,1]范围内\n",
    "        return self.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73adb25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        \n",
    "        # 检查文件夹是否存在\n",
    "        if not self.image_dir.exists():\n",
    "            raise FileNotFoundError(f\"Image directory '{image_dir}' does not exist\")\n",
    "        \n",
    "        # 获取支持的图像文件\n",
    "        self.images = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
    "        \n",
    "        # 检查是否有图像文件\n",
    "        if len(self.images) == 0:\n",
    "            raise ValueError(f\"No supported image files (.png, .jpg, .jpeg, .bmp) were found in image directory '{image_dir}'\")\n",
    "        \n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        logger.info(f\"{len(self.images)} images loaded\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        # try:\n",
    "        #     image = Image.open(img_path).convert('RGB')  # 确保图像是RGB格式\n",
    "        #     image_tensor = self.transform(image)\n",
    "        #     return image_tensor\n",
    "        # except Exception as e:\n",
    "        #     logger.error(f\"Error loading image '{img_path}': {e}\")\n",
    "        #     # 返回一个空白图像作为替代\n",
    "        #     return torch.zeros((3, 256, 256))\n",
    "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52a4c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mscdae(model, train_loader, criterion, optimizer, device, epochs=50, save_path='checkpoints'):\n",
    "    # 创建保存检查点的目录\n",
    "    save_dir = Path(save_path)\n",
    "    save_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            # 将数据移至设备\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # 前向传播\n",
    "            reconstructed = model(batch)\n",
    "            # 计算损失\n",
    "            loss = criterion(reconstructed, batch)\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # 打印批次进度\n",
    "            if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == len(train_loader):\n",
    "                logger.info(f'Epoch [{epoch+1}/{epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        logger.info(f'Epoch [{epoch+1}/{epochs}], Average Loss: {avg_loss:.4f}')\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_loss,\n",
    "            }, save_dir / 'best_model.pth')\n",
    "            logger.info(f'The best model has been saved, Loss: {best_loss:.4f}')\n",
    "        \n",
    "        # 每10个epoch保存一次检查点\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_loss,\n",
    "            }, save_dir / f'checkpoint_epoch_{epoch+1}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa6c27bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_defects(model, image, device, threshold_factor=2.0):\n",
    "    # 确保模型在评估模式\n",
    "    model.eval()\n",
    "    \n",
    "    # 将图像移至设备\n",
    "    image = image.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 获取重建图像\n",
    "        reconstructed = model(image.unsqueeze(0)).squeeze(0)\n",
    "        \n",
    "        # 计算重建误差\n",
    "        error_map = torch.abs(image - reconstructed)\n",
    "        \n",
    "        # 计算每个通道的误差统计\n",
    "        if error_map.dim() > 2:  # 多通道图像\n",
    "            # 转换为灰度误差图\n",
    "            error_map = torch.mean(error_map, dim=0)\n",
    "        \n",
    "        # 设置自适应阈值\n",
    "        threshold = error_map.mean() + threshold_factor * error_map.std()\n",
    "        defect_mask = error_map > threshold\n",
    "        \n",
    "        # 返回结果\n",
    "        return {\n",
    "            'original': image.cpu(),\n",
    "            'reconstructed': reconstructed.cpu(),\n",
    "            'error_map': error_map.cpu(),\n",
    "            'defect_mask': defect_mask.cpu(),\n",
    "            'threshold': threshold.item()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64923eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, model, device):\n",
    "    # 加载模型检查点\n",
    "    try:\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        logger.info(f\"Model loaded from '{model_path}', Epoch: {checkpoint['epoch']}, Loss: {checkpoint['loss']:.4f}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load model: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aef9e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 09:07:08,713 - MscdaeModule - INFO - Device used: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f\"Device used: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2d6bdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 09:07:08,777 - MscdaeModule - INFO - Traindata used: data/train\n",
      "2025-05-20 09:07:08,780 - MscdaeModule - INFO - Batch_size used: 16\n",
      "2025-05-20 09:07:08,783 - MscdaeModule - INFO - Epochs used: 50\n",
      "2025-05-20 09:07:08,785 - MscdaeModule - INFO - Learning_rate used: 0.001\n"
     ]
    }
   ],
   "source": [
    "# 设置参数，测试集目录\n",
    "image_dir = 'data/train'\n",
    "logger.info(f\"Traindata used: {image_dir}\")\n",
    "batch_size = 16\n",
    "logger.info(f\"Batch_size used: {batch_size}\")\n",
    "epochs = 50\n",
    "logger.info(f\"Epochs used: {epochs}\")\n",
    "learning_rate = 0.001\n",
    "logger.info(f\"Learning_rate used: {learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f531c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 09:07:08,816 - MscdaeModule - INFO - 8 images loaded\n",
      "2025-05-20 09:07:08,821 - MscdaeModule - INFO - Training set: 6 samples, Validation set: 2 samples\n"
     ]
    }
   ],
   "source": [
    "dataset = TrainDataset(image_dir)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "logger.info(f\"Training set: {train_size} samples, Validation set: {val_size} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1264f2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 09:07:08,862 - MscdaeModule - INFO - Initialize model: MSCDAE\n"
     ]
    }
   ],
   "source": [
    "# 模型初始化\n",
    "model = MSCDAE().to(device)\n",
    "logger.info(f\"Initialize model: {model.__class__.__name__}\")\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88da0b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 09:07:08,884 - MscdaeModule - INFO - Start training...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 13144) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmpty\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aiml\\skc_ai\\venv_skc_ai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1283\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\multiprocessing\\queues.py:114\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[31mEmpty\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 训练\u001b[39;00m\n\u001b[32m      2\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mStart training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtrain_mscdae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mtrain_mscdae\u001b[39m\u001b[34m(model, train_loader, criterion, optimizer, device, epochs, save_path)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     10\u001b[39m     total_loss = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 将数据移至设备\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aiml\\skc_ai\\venv_skc_ai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aiml\\skc_ai\\venv_skc_ai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aiml\\skc_ai\\venv_skc_ai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1453\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1449\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1450\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1451\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1452\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1453\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1454\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1455\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\aiml\\skc_ai\\venv_skc_ai\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1297\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) > \u001b[32m0\u001b[39m:\n\u001b[32m   1296\u001b[39m     pids_str = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(w.pid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1298\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) exited unexpectedly\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1299\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1300\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue.Empty):\n\u001b[32m   1301\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid(s) 13144) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "logger.info(\"Start training...\")\n",
    "train_mscdae(model, train_loader, criterion, optimizer, device, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bb4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存最终模型\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, 'models/final_mscdae_model.pth')\n",
    "logger.info(\"Training completed, model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ff9916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在验证集上评估\n",
    "logger.info(\"Evaluate on the validation set...\")\n",
    "model.eval()\n",
    "val_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        batch = batch.to(device)\n",
    "        reconstructed = model(batch)\n",
    "        loss = criterion(reconstructed, batch)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "avg_val_loss = val_loss / len(val_loader)\n",
    "logger.info(f\"Validation set average loss: {avg_val_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_skc_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
